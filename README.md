# TFT （temporal fusion transformer） 风速预测模型复现
## 想把代码整理到新的框架里面，用Informer的代码
## Day 11-8
因为实现的TFT模型的输出结果是可以实现多步预测的结果，每一个时间步都能输出设定步数的分位数个结果，分位数结果可以不去考虑，但是因为是实现多步预测，所以每一个序列都能输出未来几个时间步的结果，这就出现一个问题，因为采样的序列是向后滑动一个时间步，所以预测的结果会出现重复的情况，难道说预测的时候要隔出几个时间步？不太合理吧，还是要考虑未来，不如先只考虑未来几个时间步的第一个时间步的结果用来显示结果。没关系啊因为target也是有未来时间步的值的，不过问题出在预测的时候，所以在预测的时候，因为<br>
在训练的时候发现，如果训练集的数据采用随机采样的话，训练集上的损失值能稳定降低到7左右，比不随机采样损失值下降很多，说明随机插秧是有效的，但是在测试集上损失值呈现波动的状态，完全不收敛，这说明其泛化能力很差<br>
使用训练好的模型在训练集上的结果显示，损失函数应该有问题，针对模型的输出结果将现有可以用损失函数的指标封装一下， 但是模型的输出有7个，应该怎样使用呢？暂时使用第一个维度的数据，只训练这一个维度的输出结果，后面用的时候也就只用这一个维度的数据进行预测就行了
## Day 11-7
* 使用数据集测试一下提供的dataset和dataloader的迭代输出包含两个部分，(x, y)<br>
x：Dict[str: torch.Tensor] 11个分别为：
encoder_cat, encoder_cont, encoder_target, encoder_lengths, decoder_cat, decoder_cont, decoder_lengths, decoder_time_idx,
groups, target_scale<br>
y: tuple 2个：
target(torch.Tensor), weihgt一般为NAN
* forward 函数完成了，还需要调试一下，看看能不能跑通
* 模型的初始化参数直接使用Params类的实例化对象，给它传入所有的参数，包括json文件中便于调试定义的参数，以及从dataset中获得参数，以后可以考虑将dataset初始化的参数放到json文件中。
* *明天计划，想模型跑起来，前面已经实现train（），predicte()等函数应该很快就能完成整体的构架，中间可能遇到的问题就是<br>*
  * 损失函数的维度，这个因为分位数损失函数可以自己定义应该能快速解决该问题
  * 还是dataset和dateloader部分的程序，因为输入一个pd.dataframe到输出哪几种结果，以及各各种中间变量，还是很多的麻烦东西，所以这块的程序不好重写。
## Day 11-6
首先还是使用她的dataset和detaloader，但是不知道会不会出现什么不会的东西在里面导致程序跑不通<br>
所以明天需要做的第一件事就是要首先使用数据集测试一下提供的dataset和dataloader的迭代输出是什么样的<br>
然后完成相应的模型forward函数<br>
然后就是模型初始化需要的参数确定要怎样传入
## Day 11-4
昨天遇到的出现Nan值得情况，debug发现还是原始数据中出现缺失值造成的，所以在数据预处理阶段进行了线性操作，果然成功解决问题。<br>
看在训练集上的结果在25左右就不会再改变，这个值是7个分位数相加的结果，除以7之后，在训练集上的损失值重9降到3左右，这个损失值得真正物理含义应是y值吧<br>
看看添加归一化之后的情况：添加归一化之后，单从训练集上的训练几过来看，损失值的降低程度不大，具体情况要看预测结果作为对照
使用训练的LSTM模型后发现，如果使用单变量的话就是仅仅使用历史的风速数据，是能比较好的预测未来下一时间点的风速值，RMSE值大约在5.04左右<br>
但是使用多个变量输入得时候，不能很好地训练，不知道是什么原因目前。下一步的话还是复现TFT从头开始，不使用那个框架。
## Day 11-3
先在LSTM上跑一下看看结果，先不使用VMD分解，需要的话后面在加上， 现在学习一下在训练集和测试集上进行归一化和反归一化的操作，有利于训练<br>
按照现在有的思路，使用LSTM最后一层的最后的隐藏状态做预测的时候，不能让同时实现分位数和多步预测结果，首先是训练的损失函数就没法搞，所以先实现LSTM的单步预测<br>

一个问题:运行到一定阶段后，出现值为Nan的情况，现在的感觉是原始数据中出现数据值得缺失，造成结果的NaN出现，明天先来吧数据再清洗一遍，要填充一下Nan值，不然的话这没法搞啊
解决上面的问题后要把LSTM训练的evaluate和prediction的部分补全，在训练的时候要考虑是否早停的的环节防止过拟合，这个可以后面再说

## Day 11-1
* 在python文件中出现的__all__=[]可以控制使用from xxx import * 时显示的接口
## Day 10-31
完成了evaluate中内容，主要包括模型参数的保存，以及结果的打印，学习了使用os.path将相关的文件路径操作方法<br>
问题loss损失函数需要重写
## Day 10-30
输出的结果是对应7个分位数的结果，但是在及逆行方向传播的时候是将整个batch_size(0de结果进行求和，或者进行求和后取平均得到的一个值，这样就可以进行反向传播了，现在的问题是，在进行模型评价的时候怎样使用特定的评价指标MSE,RMSE 等进行评价，并且保存chickpoint
## Day 10-28
还是决定自己写训练过程部分函数，明天要把使用分位数回归的方法进行测试，搞明白输出的losses是一个怎样的结果，个人感觉应该是一个列表，每一项都是特定分位数时的损失值，默认的情况下计算7个分位数的结果，所以每个时间步有7损失结果，所以要怎样进行反向传播呢。
## Day 10-27
#### 一、主要完成任务：
* 实现对原始风速数据的VMD分解，主要使用vmdpy库进行
* 完成了数据的预处理环节，使用**date_processed**函数实现
* 实现dataloader， 在**my_dataloader**函数中实现<br>
下一步任务完成训练环节的代码，要完整可复现的程度，便于以后重复使用<br>
* **学习使用logg模块打印信息** ：Logging中有NOTSET < DEBUG < INFO < WARNING < ERROR < CRITICAL五种级别
* **学习使用argparse模块**：使用指南
  * import模块： import argparse
  * 获取解析器对象： argparse.ArgumentParser
  * 利用解析器对象内建方法**add_argument**, 添加参数解析规则
  * 利用解析器对象内建方法**parse_args**, 解析参数，获取解析结果对象**args**
  * 从解析对象**args**中获取参数值
* **早停法** 减少过拟合的一种方法，主要做法在训练的时候计算模型在验证集上的表现，当模型在验证集上的表现开始下降的时候，停止训练，现在主要有三种停止标准
#### 如何使用早停法
我们需要一个停止的标准来实施早停法，因此，我们希望它可以产生最低的繁华错误，同时也可以有最好的性价比，即给定泛化错误下的最小训练时间
##### 停止标准简介
停止标准有很多，也很灵活，大约有三种。在给出早停法的具体标准之前，我们先确定一下符号。假设我们使用E作为训练算法的误差函数，那么Etr是训练数据上的误差，Ete是测试集上的误差。实际情况下我们并不能知道泛化误差，因此我们使用验证集误差来估计它。

**第一类停止标准**

假设Eopt(t)是在迭代次数t时取得最好的验证集误差：

```math
E_{opt}(t) := \text{min}_{t'\leq t}E_{va}(t')
```

我们定义一个新变量叫**泛化损失（generalization loss）**，它描述的是在当前迭代周期t中，泛化误差相比较目前的最低的误差的一个增长率：

```math
GL(t) = 100 \cdot \big( \frac{E_{va}(t)}{E_{opt}(t)} - 1 \big)
```

较高的泛化损失显然是停止训练的一个候选标准，因为它直接表明了过拟合。这就是第一类的停止标准，即当泛化损失超过一定阈值的时候，停止训练。我们用$GL\_{\alpha}$来定义，即当$GL\_{\alpha}$大于一定值$\alpha$的时候，停止训练。

**第二类停止标准**

然而，当训练的速度很快的时候，我们可能希望模型继续训练。因为如果训练错误依然下降很快，那么泛化损失有很大概率被修复。我们通常会**假设过拟合只会在训练错误降低很慢的时候出现**。在这里，我们定义一个$k$周期，以及基于周期的一个新变量**度量进展（measure progress）**：

```math
P_k(t) = 1000 \cdot \big( \frac{ \sum_{t' = t-k+1}^t E_{tr}(t') }{ k \cdot min_{t' = t-k+1}^t E_{tr}(t') } -1 \big)
```

它表达的含义是，当前的指定迭代周期内的平均训练错误比该期间最小的训练错误大多少。注意，当训练过程不稳定的时候，这个measure progress结果可能很大，其中训练错误会变大而不是变小。实际中，很多算法都由于选择了不适当的较大的步长而导致这样的抖动。除非全局都不稳定，否则在较长的训练之后，measure progress结果趋向于0（其实这个就是度量训练集错误在某段时间内的平均下降情况）。由此，我们引入了第二个停止标准，即泛化损失和进展的商$PQ\_{\alpha}$大于指定值的时候停止，即$\frac{GL(t)}{P\_k(t)} \gt \alpha$

**第三类停止标准**
第三类停止标准则完全依赖于泛化错误的变化，即当泛化错误在连续$s$个周期内增长的时候停止（$UP$）。

当验证集错误在连续$s$个周期内出现增长的时候，我们假设这样的现象表明了过拟合，它与错误增长了多大独立。这个停止标准可以度量局部的变化，因此可以用在剪枝算法中，即在训练阶段，允许误差可以比前面最小值高很多时候保留。
## Day 10-24
* 使用cygwin下载了风速预测中使用的一个数据集，下一步要进行VMD分解按照论文中的参数
